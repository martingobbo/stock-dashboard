{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9763b5b9-50ef-4747-bb82-763bc89d3bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date window: 2025-06-27 → 2025-10-01\n",
      "Ultra rows: 3071\n",
      "Bearish rows: 1254\n",
      "Breakout Down rows: 615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  ticker  signal                 date\n",
       " 0    JBL  85.323  2025-06-27 00:00:00\n",
       " 1    HWM  82.126  2025-06-27 00:00:00\n",
       " 2    RCL  81.095  2025-06-27 00:00:00\n",
       " 3   COIN  79.378  2025-06-27 00:00:00\n",
       " 4    NRG  78.034  2025-06-27 00:00:00,\n",
       "   ticker  signal                 date\n",
       " 0   BF.B  78.492  2025-06-27 00:00:00\n",
       " 1    PCG  70.110  2025-06-27 00:00:00\n",
       " 2   ENPH  69.813  2025-06-27 00:00:00\n",
       " 3    DOW  68.341  2025-06-27 00:00:00\n",
       " 4    CPB  67.336  2025-06-27 00:00:00,\n",
       "   ticker  signal                 date\n",
       " 0      K  46.561  2025-06-27 00:00:00\n",
       " 1    LMT  41.430  2025-06-27 00:00:00\n",
       " 2    EOG  28.335  2025-06-27 00:00:00\n",
       " 3    XOM  22.807  2025-06-27 00:00:00\n",
       " 4    PFE  22.582  2025-06-27 00:00:00)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HISTORICAL LOAD OF SIGNAL STRENGTH\n",
    "\n",
    "# --- Signal Strength over a Date Range (Ultra Bullish / Bearish / Breakout Down) ---\n",
    "# Requirements: duckdb, pandas, numpy\n",
    "import duckdb, pandas as pd, numpy as np\n",
    "\n",
    "# ====== USER SETTINGS ======\n",
    "DB_PATH    = \"/Users/martingobbo/stock-dashboard/data/serving/analytics.duckdb\"\n",
    "START_DATE = \"2025-06-27\"   # <-- set your start date (YYYY-MM-DD)\n",
    "END_DATE   = None           # <-- set \"YYYY-MM-DD\" to cap the range, or None to use latest available\n",
    "# ===========================\n",
    "\n",
    "# ====== DB CONNECT ======\n",
    "con = duckdb.connect(DB_PATH, read_only=True)\n",
    "\n",
    "# ====== CONFIG — metric codes exactly matching dim_metric.metric_code ======\n",
    "METRIC_CODES = [\n",
    "    # Price\n",
    "    'moving_avg_20d','moving_avg_50d','moving_avg_200d',\n",
    "    '5_day_range_pos',\n",
    "    'change_10dayret',\n",
    "    'slope_over60_of_logprice','prior_slope_over60_of_logprice','60d_return_accel',\n",
    "    '10_day_ret','60_day_ret','200_day_ret','300_day_ret',\n",
    "    # Volume\n",
    "    'abn_vol_60d',\n",
    "    '60d_price_dollarVolume_correlation',\n",
    "    '252d_dollar_volume_accel',\n",
    "    '60d_dollar_volume_SMA','252d_dollar_volume_SMA',\n",
    "    # Volatility\n",
    "    '252d_upsidevolatility','252d_downsidedeviation',\n",
    "    'slope_over20_of_60d_volatility','slope_over60_of_252d_volatility',\n",
    "    '5d_EMA_15dayvolatility','60d_volatility',\n",
    "    '60_10_highlowrange_zscore',\n",
    "    # Drawdown\n",
    "    '750d_drawdown',\n",
    "    'drawdown_percent'\n",
    "]\n",
    "\n",
    "# ====== Helpers ======\n",
    "def clamp(v, lo, hi):\n",
    "    try:\n",
    "        return max(lo, min(hi, v))\n",
    "    except Exception:\n",
    "        return lo\n",
    "\n",
    "def nz(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    try:\n",
    "        xx = float(x)\n",
    "        if np.isnan(xx):\n",
    "            return None\n",
    "        return xx\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def g(row, key):\n",
    "    return nz(row.get(key))\n",
    "\n",
    "# ====== 1) Resolve metric ids (once) ======\n",
    "codes_df = pd.DataFrame({'metric_code': METRIC_CODES})\n",
    "con.register('codes_df', codes_df)\n",
    "\n",
    "met = con.execute(\"\"\"\n",
    "    SELECT d.metric_code, d.metric_id\n",
    "    FROM dim_metric d\n",
    "    JOIN codes_df c ON c.metric_code = d.metric_code\n",
    "\"\"\").df()\n",
    "\n",
    "if met.empty:\n",
    "    raise RuntimeError(\"No metric_id found for the requested METRIC_CODES in dim_metric.\")\n",
    "\n",
    "code_to_id = dict(zip(met.metric_code, met.metric_id))\n",
    "id_to_code = dict(zip(met.metric_id, met.metric_code))\n",
    "metric_id_csv = \",\".join(str(i) for i in met.metric_id)\n",
    "\n",
    "# ====== 2) Determine date range ======\n",
    "latest_dt = con.execute(f\"\"\"\n",
    "    SELECT CAST(MAX(CAST(dt AS DATE)) AS DATE) AS max_dt\n",
    "    FROM fact_metric_daily\n",
    "    WHERE metric_id IN ({metric_id_csv})\n",
    "\"\"\").fetchone()[0]\n",
    "if latest_dt is None:\n",
    "    raise RuntimeError(\"Could not find any dt in fact_metric_daily for the requested metrics.\")\n",
    "\n",
    "date_max = latest_dt if END_DATE is None else END_DATE\n",
    "\n",
    "dates_df = con.execute(f\"\"\"\n",
    "    SELECT DISTINCT CAST(dt AS DATE) AS d\n",
    "    FROM fact_metric_daily\n",
    "    WHERE metric_id IN ({metric_id_csv})\n",
    "      AND CAST(dt AS DATE) >= DATE '{START_DATE}'\n",
    "      AND CAST(dt AS DATE) <= DATE '{date_max}'\n",
    "    ORDER BY d\n",
    "\"\"\").df()\n",
    "\n",
    "if dates_df.empty:\n",
    "    raise RuntimeError(f\"No dates in fact_metric_daily between {START_DATE} and {date_max} for requested metrics.\")\n",
    "\n",
    "available_dates = [str(d) for d in dates_df['d'].tolist()]\n",
    "\n",
    "# ====== 3) Scoring functions (same as your single-day version) ======\n",
    "\n",
    "# ---- ULTRA BULLISH ----\n",
    "def gate_ultra(row):\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    zAbn = g(row,'abn_vol_60d')\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    priceOK = (r10 is not None and r10 >= 0.02) and (r60 is not None and r60 >= 0.05)\n",
    "    volOK   = ((zAbn is not None and zAbn > 0.3) or (corr is not None and corr > 0.5))\n",
    "    return priceOK and volOK\n",
    "\n",
    "def score_price_ultra(row):\n",
    "    pts = 0.0\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "    if ma20 is not None and ma50 not in (None, 0):\n",
    "        rel = (ma20/ma50) - 1\n",
    "        if rel > 0:\n",
    "            pts += 6 * clamp(rel/0.10, 0, 1)\n",
    "    if ma50 is not None and ma200 not in (None, 0):\n",
    "        rel = (ma50/ma200) - 1\n",
    "        if rel > 0:\n",
    "            pts += 6 * clamp(rel/0.10, 0, 1)\n",
    "    pos = g(row,'5_day_range_pos') or 0\n",
    "    pos = clamp(pos, 0, 1)\n",
    "    pts += 8 * pos\n",
    "    ch10 = g(row,'change_10dayret')\n",
    "    if ch10 is not None and ch10 > 0:\n",
    "        pts += 4\n",
    "    s60  = g(row,'slope_over60_of_logprice')\n",
    "    s60p = g(row,'prior_slope_over60_of_logprice')\n",
    "    accel60 = g(row,'60d_return_accel')\n",
    "    if (s60 is not None and s60p is not None and (s60 - s60p) > 0) or (accel60 is not None and accel60 > 0):\n",
    "        pts += 3\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    if r10 is not None and r10 > 0:\n",
    "        pts += 5 * clamp(r10/0.10, 0, 1)\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    if r60 is not None and r60 > 0:\n",
    "        pts += 6 * clamp(r60/0.25, 0, 1)\n",
    "    r300 = g(row,'300_day_ret')\n",
    "    if r300 is not None and r300 > 0:\n",
    "        pts += 4 * clamp(r300/0.50, 0, 1)\n",
    "    return clamp(pts, 0, 45)\n",
    "\n",
    "def score_volume_ultra(row):\n",
    "    pts = 0.0\n",
    "    z = g(row,'abn_vol_60d')\n",
    "    if z is not None:\n",
    "        pts += 8 * clamp(z/2, 0, 1)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    if corr is not None:\n",
    "        pts += 7 * clamp(corr, 0, 1)\n",
    "    accel252 = g(row,'252d_dollar_volume_accel')\n",
    "    if accel252 is not None and accel252 > 0:\n",
    "        pts += 5\n",
    "    sma60, sma252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    if sma60 is not None and sma252 not in (None, 0):\n",
    "        rel = (sma60/sma252) - 1\n",
    "        if rel > 0:\n",
    "            pts += 8 * clamp(rel/0.20, 0, 1)\n",
    "    return clamp(pts, 0, 28)\n",
    "\n",
    "def score_vola_ultra(row):\n",
    "    pts = 0.0\n",
    "    up252, dn252 = g(row,'252d_upsidevolatility'), g(row,'252d_downsidedeviation')\n",
    "    if up252 is not None and dn252 not in (None, 0) and (up252/dn252) > 1:\n",
    "        pts += 5\n",
    "    slope60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    if slope60 is not None and slope60 <= 0:\n",
    "        pts += 5\n",
    "    slope252 = g(row,'slope_over60_of_252d_volatility')\n",
    "    if slope252 is not None and slope252 < 0:\n",
    "        pts += 4\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    if ema15 is not None and vol60 not in (None, 0) and (ema15/vol60) < 1:\n",
    "        pts += 8\n",
    "    return clamp(pts, 0, 22)\n",
    "\n",
    "def score_drawdown_ultra(row):\n",
    "    pts = 0.0\n",
    "    dd750 = g(row,'750d_drawdown')\n",
    "    if dd750 is not None:\n",
    "        pts += 2 * (1 - clamp(abs(dd750)/0.40, 0, 1))\n",
    "    dd100 = g(row,'drawdown_percent')\n",
    "    if dd100 is not None:\n",
    "        pts += 3 * (1 - clamp(abs(dd100)/0.20, 0, 1))\n",
    "    return clamp(pts, 0, 5)\n",
    "\n",
    "# ---- BEARISH ----\n",
    "def gate_bearish(row):\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    zAbn = g(row,'abn_vol_60d')\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    priceOK = (r10 is not None and r10 <= -0.02) and (r60 is not None and r60 <= -0.05)\n",
    "    volOK   = ((zAbn is not None and zAbn > 0.3) or (corr is not None and corr > 0.5))\n",
    "    return priceOK and volOK\n",
    "\n",
    "def score_price_bearish(row):\n",
    "    pts = 0.0\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "    if ma20 is not None and ma50 not in (None, 0):\n",
    "        rel = (ma20/ma50) - 1\n",
    "        if rel < 0:\n",
    "            pts += 6 * clamp((-rel)/0.10, 0, 1)\n",
    "    if ma50 is not None and ma200 not in (None, 0):\n",
    "        rel2 = (ma50/ma200) - 1\n",
    "        if rel2 < 0:\n",
    "            pts += 6 * clamp((-rel2)/0.10, 0, 1)\n",
    "    pos = g(row,'5_day_range_pos') or 0\n",
    "    pos = clamp(pos, 0, 1)\n",
    "    pts += 8 * (1 - pos)\n",
    "    ch10 = g(row,'change_10dayret')\n",
    "    if ch10 is not None and ch10 < 0:\n",
    "        pts += 4\n",
    "    s60  = g(row,'slope_over60_of_logprice')\n",
    "    s60p = g(row,'prior_slope_over60_of_logprice')\n",
    "    accel60 = g(row,'60d_return_accel')\n",
    "    if (s60 is not None and s60p is not None and (s60 - s60p) < 0) or (accel60 is not None and accel60 < 0):\n",
    "        pts += 3\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    if r10 is not None and r10 < 0:\n",
    "        pts += 5 * clamp((-r10)/0.10, 0, 1)\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    if r60 is not None and r60 < 0:\n",
    "        pts += 6 * clamp((-r60)/0.25, 0, 1)\n",
    "    r300 = g(row,'300_day_ret')\n",
    "    if r300 is not None and r300 < 0:\n",
    "        pts += 4 * clamp((-r300)/0.50, 0, 1)\n",
    "    return clamp(pts, 0, 45)\n",
    "\n",
    "def score_volume_bearish(row):\n",
    "    pts = 0.0\n",
    "    z = g(row,'abn_vol_60d')\n",
    "    if z is not None:\n",
    "        pts += 8 * clamp(z/2, 0, 1)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    if corr is not None:\n",
    "        pts += 7 * clamp(-corr, 0, 1)\n",
    "    accel252 = g(row,'252d_dollar_volume_accel')\n",
    "    if accel252 is not None and accel252 > 0:\n",
    "        pts += 5\n",
    "    sma60, sma252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    if sma60 is not None and sma252 not in (None, 0):\n",
    "        rel = (sma60/sma252) - 1\n",
    "        if rel > 0:\n",
    "            pts += 8 * clamp(rel/0.20, 0, 1)\n",
    "    return clamp(pts, 0, 28)\n",
    "\n",
    "def score_vola_bearish(row):\n",
    "    pts = 0.0\n",
    "    up252, dn252 = g(row,'252d_upsidevolatility'), g(row,'252d_downsidedeviation')\n",
    "    if up252 is not None and dn252 not in (None, 0) and (up252/dn252) < 1:\n",
    "        pts += 5\n",
    "    slope60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    if slope60 is not None and slope60 >= 0:\n",
    "        pts += 5\n",
    "    slope252 = g(row,'slope_over60_of_252d_volatility')\n",
    "    if slope252 is not None and slope252 > 0:\n",
    "        pts += 4\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    if ema15 is not None and vol60 not in (None, 0) and (ema15/vol60) > 1:\n",
    "        pts += 8\n",
    "    return clamp(pts, 0, 22)\n",
    "\n",
    "def score_drawdown_bearish(row):\n",
    "    pts = 0.0\n",
    "    dd750 = g(row,'750d_drawdown')\n",
    "    if dd750 is not None:\n",
    "        pts += 2 * clamp(abs(dd750)/0.40, 0, 1)\n",
    "    dd100 = g(row,'drawdown_percent')\n",
    "    if dd100 is not None:\n",
    "        pts += 3 * clamp(abs(dd100)/0.20, 0, 1)\n",
    "    return clamp(pts, 0, 5)\n",
    "\n",
    "# ---- BREAKOUT DOWN ----\n",
    "def gate_breakdown(row):\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    pos5 = g(row,'5_day_range_pos')\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "\n",
    "    priceFresh = (r10 is not None and r10 < 0.02) and (r60 is not None and r60 > -0.10)\n",
    "    nearLows = (pos5 is not None and pos5 <= 0.15)\n",
    "    freshFlip = ((ma20 is not None and ma50 is not None and ma20 < ma50) or\n",
    "                 (ma50 is not None and ma200 is not None and ma50 < ma200))\n",
    "\n",
    "    zAbn = g(row,'abn_vol_60d')\n",
    "    dv60, dv252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    liqUpshift = (dv60 is not None and dv252 not in (None, 0) and (dv60/dv252) >= 1.15)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    volConfirm = ((zAbn is not None and zAbn >= 0.5) or liqUpshift or (corr is not None and corr <= -0.2))\n",
    "\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    shortVsInter = (ema15 is not None and vol60 not in (None, 0) and (ema15/vol60) > 1)\n",
    "\n",
    "    slope20of60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    zRange = g(row,'60_10_highlowrange_zscore')\n",
    "    dd100 = g(row,'drawdown_percent')\n",
    "    volaConfirm = (\n",
    "        shortVsInter\n",
    "        or (slope20of60 is not None and slope20of60 >= 0)\n",
    "        or (zRange is not None and zRange >= 0.25)\n",
    "        or (dd100 is not None and dd100 > 0.15)\n",
    "    )\n",
    "    return priceFresh and nearLows and freshFlip and volConfirm and volaConfirm\n",
    "\n",
    "def score_price_breakdown(row):\n",
    "    pts = 0.0\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "    if ma20 is not None and ma50 not in (None, 0):\n",
    "        rel = (ma20/ma50) - 1\n",
    "        if rel < 0:\n",
    "            pts += 6 * clamp((-rel)/0.05, 0, 1)\n",
    "    if ma50 is not None and ma200 not in (None, 0):\n",
    "        rel2 = (ma50/ma200) - 1\n",
    "        if rel2 < 0:\n",
    "            pts += 6 * clamp((-rel2)/0.05, 0, 1)\n",
    "    s60  = g(row,'slope_over60_of_logprice')\n",
    "    s60p = g(row,'prior_slope_over60_of_logprice')\n",
    "    if s60 is not None and s60p is not None:\n",
    "        delta = s60 - s60p\n",
    "        if delta <= 0:\n",
    "            pts += 10 * clamp((-delta)/0.02, 0, 1)\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    if r10 is not None and r10 < -0.02:\n",
    "        pts += 5\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    if r60 is not None:\n",
    "        if r60 > 0:\n",
    "            pts += 5\n",
    "        elif r60 >= -0.10:\n",
    "            pts += 2\n",
    "    r200 = g(row,'200_day_ret')\n",
    "    if r200 is not None:\n",
    "        pts += (8 if r200 > 0 else 3)\n",
    "    return clamp(pts, 0, 40)\n",
    "\n",
    "def score_volume_breakdown(row):\n",
    "    pts = 0.0\n",
    "    z = g(row,'abn_vol_60d')\n",
    "    if z is not None:\n",
    "        pts += 10 * clamp(z/1.85, 0, 1)\n",
    "    dv60, dv252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    if dv60 is not None and dv252 not in (None, 0):\n",
    "        rel = (dv60/dv252) - 1\n",
    "        pts += 8 * clamp(rel/0.20, 0, 1)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    if corr is not None:\n",
    "        pts += 7 * clamp(-corr, 0, 1)\n",
    "    return clamp(pts, 0, 25)\n",
    "\n",
    "def score_vola_breakdown(row):\n",
    "    pts = 0.0\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    if ema15 is not None and vol60 not in (None, 0):\n",
    "        ratio = ema15/vol60\n",
    "        if ratio > 1:\n",
    "            pts += 10 * clamp((ratio - 1)/0.50, 0, 1)\n",
    "    slope20of60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    if slope20of60 is not None and slope20of60 >= 0:\n",
    "        pts += 8 * clamp(slope20of60/0.02, 0, 1)\n",
    "    zRange = g(row,'60_10_highlowrange_zscore')\n",
    "    if zRange is not None:\n",
    "        pts += 7 * clamp(zRange/1.8, 0, 1)\n",
    "    return clamp(pts, 0, 25)\n",
    "\n",
    "def score_drawdown_breakdown(row):\n",
    "    pts = 0.0\n",
    "    dd = g(row,'drawdown_percent')\n",
    "    if dd is not None and dd <= 0.20:\n",
    "        pts += 6 * (1 - clamp(abs(dd)/0.20, 0, 1))\n",
    "    dd750 = g(row,'750d_drawdown')\n",
    "    if dd750 is not None:\n",
    "        pts += 4 * (1 - clamp(abs(dd750)/0.40, 0, 1))\n",
    "    return clamp(pts, 0, 10)\n",
    "\n",
    "# ====== 4) Iterate dates, score, collect ======\n",
    "ultra_all, bearish_all, breakdown_all = [], [], []\n",
    "\n",
    "for d in available_dates:\n",
    "    vals = con.execute(f\"\"\"\n",
    "        SELECT t.ticker, f.metric_id, f.value\n",
    "        FROM fact_metric_daily f\n",
    "        JOIN dim_ticker t USING (ticker_id)\n",
    "        WHERE CAST(f.dt AS DATE) = DATE '{d}'\n",
    "          AND f.metric_id IN ({metric_id_csv})\n",
    "          AND t.ticker IS NOT NULL AND LENGTH(TRIM(t.ticker)) > 0\n",
    "    \"\"\").df()\n",
    "\n",
    "    if vals.empty:\n",
    "        continue\n",
    "\n",
    "    vals[\"metric_code\"] = vals[\"metric_id\"].map(id_to_code)\n",
    "    wide = vals.pivot_table(index=\"ticker\", columns=\"metric_code\", values=\"value\", aggfunc=\"first\").reset_index()\n",
    "\n",
    "    # Ensure all required columns exist\n",
    "    for col in METRIC_CODES:\n",
    "        if col not in wide.columns:\n",
    "            wide[col] = np.nan\n",
    "\n",
    "    records = wide.to_dict(orient=\"records\")\n",
    "\n",
    "    for r in records:\n",
    "        ticker = r[\"ticker\"]\n",
    "\n",
    "        if gate_ultra(r):\n",
    "            total = clamp(\n",
    "                score_price_ultra(r) + score_volume_ultra(r) + score_vola_ultra(r) + score_drawdown_ultra(r),\n",
    "                0, 100\n",
    "            )\n",
    "            ultra_all.append({\"ticker\": ticker, \"signal\": round(total, 3), \"date\": d})\n",
    "\n",
    "        if gate_bearish(r):\n",
    "            total = clamp(\n",
    "                score_price_bearish(r) + score_volume_bearish(r) + score_vola_bearish(r) + score_drawdown_bearish(r),\n",
    "                0, 100\n",
    "            )\n",
    "            bearish_all.append({\"ticker\": ticker, \"signal\": round(total, 3), \"date\": d})\n",
    "\n",
    "        if gate_breakdown(r):\n",
    "            total = clamp(\n",
    "                score_price_breakdown(r) + score_volume_breakdown(r) + score_vola_breakdown(r) + score_drawdown_breakdown(r),\n",
    "                0, 100\n",
    "            )\n",
    "            breakdown_all.append({\"ticker\": ticker, \"signal\": round(total, 3), \"date\": d})\n",
    "\n",
    "# ====== 5) Final DataFrames across the whole period ======\n",
    "ultra_signals_df    = pd.DataFrame(ultra_all).sort_values([\"date\",\"signal\",\"ticker\"], ascending=[True, False, True]).reset_index(drop=True)\n",
    "bearish_signals_df  = pd.DataFrame(bearish_all).sort_values([\"date\",\"signal\",\"ticker\"], ascending=[True, False, True]).reset_index(drop=True)\n",
    "breakdown_signals_df= pd.DataFrame(breakdown_all).sort_values([\"date\",\"signal\",\"ticker\"], ascending=[True, False, True]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Date window: {START_DATE} → {date_max}\")\n",
    "print(\"Ultra rows:\", len(ultra_signals_df))\n",
    "print(\"Bearish rows:\", len(bearish_signals_df))\n",
    "print(\"Breakout Down rows:\", len(breakdown_signals_df))\n",
    "\n",
    "# Optional: preview heads\n",
    "ultra_signals_df.head(), bearish_signals_df.head(), breakdown_signals_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df321b48-cb2c-4035-9e36-1244264e531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DAILY PORTFOLIO (single output: daily_portfolio) =========================\n",
    "import pandas as pd\n",
    "from typing import Iterable, Optional, Dict, Any\n",
    "\n",
    "# ========= CONFIG YOU CAN TUNE ========\n",
    "# Choose which DataFrame supplies (ticker, signal, date)\n",
    "# e.g., ultra_signals_df, bearish_signals_df, breakout_signals_df, etc.\n",
    "INPUT_DF = ultra_signals_df\n",
    "\n",
    "TOP_N = 5                  # Ignored if KEEP_ALL=True\n",
    "KEEP_ALL = True           # If True, keep all tickers per day (after rules/cooldowns)\n",
    "RULES: Dict[str, Any] = {\n",
    "    \"min_signal\": 67,    # e.g., 50.0  (None disables)\n",
    "    \"include\": None,       # e.g., {\"AAPL\",\"MSFT\",\"NVDA\"}  (None disables)\n",
    "    \"exclude\": None,       # e.g., {\"TSLA\"}                (None disables)\n",
    "    \"cool_down_days\": 0,   # e.g., 3  (0 disables)\n",
    "}\n",
    "# =====================================\n",
    "\n",
    "def _normalize_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    x = df.copy()\n",
    "    x[\"date\"] = pd.to_datetime(x[\"date\"]).dt.date\n",
    "    return x\n",
    "\n",
    "def _apply_basic_rules(\n",
    "    df: pd.DataFrame,\n",
    "    min_signal: Optional[float],\n",
    "    include: Optional[Iterable[str]],\n",
    "    exclude: Optional[Iterable[str]],\n",
    ") -> pd.DataFrame:\n",
    "    x = df.copy()\n",
    "    if min_signal is not None:\n",
    "        x = x.loc[x[\"signal\"] >= float(min_signal)]\n",
    "    if include is not None:\n",
    "        inc = set(include)\n",
    "        x = x.loc[x[\"ticker\"].isin(inc)]\n",
    "    if exclude is not None:\n",
    "        exc = set(exclude)\n",
    "        x = x.loc[~x[\"ticker\"].isin(exc)]\n",
    "    return x\n",
    "\n",
    "def build_daily_portfolio(\n",
    "    signals_df: pd.DataFrame,\n",
    "    top_n: int = 5,\n",
    "    keep_all: bool = False,\n",
    "    rules: Optional[Dict[str, Any]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns ONE DataFrame named daily_portfolio with columns:\n",
    "      - date, rank, ticker, signal\n",
    "    Notes:\n",
    "      - If keep_all=True, returns all tickers per day (still sorted by signal desc).\n",
    "      - cool_down_days (if >0) prevents a ticker from reappearing within K prior days.\n",
    "    \"\"\"\n",
    "    if rules is None:\n",
    "        rules = {}\n",
    "\n",
    "    df = _normalize_dates(signals_df)\n",
    "    df = _apply_basic_rules(\n",
    "        df,\n",
    "        rules.get(\"min_signal\"),\n",
    "        rules.get(\"include\"),\n",
    "        rules.get(\"exclude\"),\n",
    "    )\n",
    "\n",
    "    # Sort so strongest first within each day\n",
    "    df = df.sort_values([\"date\", \"signal\"], ascending=[True, False])\n",
    "\n",
    "    # Optional cool-down (walk forward day-by-day, ban recent selections)\n",
    "    k = int(rules.get(\"cool_down_days\", 0) or 0)\n",
    "    if k > 0:\n",
    "        kept_rows = []\n",
    "        for day, chunk in df.groupby(\"date\", sort=True):\n",
    "            if kept_rows:\n",
    "                kept = pd.concat(kept_rows, ignore_index=True)\n",
    "                recent_days = sorted(kept[\"date\"].unique())[-k:]\n",
    "                banned = set(kept.loc[kept[\"date\"].isin(recent_days), \"ticker\"])\n",
    "            else:\n",
    "                banned = set()\n",
    "            allowed = chunk.loc[~chunk[\"ticker\"].isin(banned)]\n",
    "            kept_rows.append(allowed)\n",
    "        df = pd.concat(kept_rows, ignore_index=True).sort_values([\"date\", \"signal\"], ascending=[True, False])\n",
    "\n",
    "    # Pick rows per day\n",
    "    if keep_all:\n",
    "        selected = df\n",
    "    else:\n",
    "        selected = df.groupby(\"date\", as_index=False).head(top_n)\n",
    "\n",
    "    # Rank within each day (1 = strongest)\n",
    "    selected = selected.copy()\n",
    "    selected[\"rank\"] = selected.groupby(\"date\")[\"signal\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "\n",
    "    daily_portfolio = selected[[\"date\", \"rank\", \"ticker\", \"signal\"]].sort_values([\"date\", \"rank\"])\n",
    "    return daily_portfolio\n",
    "\n",
    "# ====== RUN IT on your chosen INPUT_DF ======\n",
    "daily_portfolio = build_daily_portfolio(\n",
    "    INPUT_DF,\n",
    "    top_n=TOP_N,\n",
    "    keep_all=KEEP_ALL,\n",
    "    rules=RULES,\n",
    ")\n",
    "\n",
    "# (Optional) display in notebooks\n",
    "# from IPython.display import display\n",
    "# display(daily_portfolio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9c75dc-423f-4928-aa3e-31ed42d20c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>ticker</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>1</td>\n",
       "      <td>JBL</td>\n",
       "      <td>85.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>2</td>\n",
       "      <td>HWM</td>\n",
       "      <td>82.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>3</td>\n",
       "      <td>RCL</td>\n",
       "      <td>81.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>4</td>\n",
       "      <td>COIN</td>\n",
       "      <td>79.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>5</td>\n",
       "      <td>NRG</td>\n",
       "      <td>78.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  rank ticker  signal\n",
       "0  2025-06-27     1    JBL  85.323\n",
       "1  2025-06-27     2    HWM  82.126\n",
       "2  2025-06-27     3    RCL  81.095\n",
       "3  2025-06-27     4   COIN  79.378\n",
       "4  2025-06-27     5    NRG  78.034"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b00fb6d-1639-4dac-8f10-f5f2dab82c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equity curve (tail):\n",
      "          date  equity_value       cash  total_value  num_names  \\\n",
      "56  2025-09-18    121.237801   0.971838   122.209639          6   \n",
      "57  2025-09-19    123.005568   0.304438   123.310007          7   \n",
      "58  2025-09-22    123.722374   0.319477   124.041851          7   \n",
      "59  2025-09-23    123.294572   0.411301   123.705873         12   \n",
      "60  2025-09-24    122.381282   0.261872   122.643155         11   \n",
      "61  2025-09-25    122.905773  -2.429742   120.476032         11   \n",
      "62  2025-09-26    121.045727  -0.074009   120.971718          8   \n",
      "63  2025-09-29    119.702545   2.111428   121.813973          3   \n",
      "64  2025-09-30    123.005388  -1.089032   121.916356          4   \n",
      "65  2025-10-01    127.555404 -31.302840    96.252564          5   \n",
      "\n",
      "    gross_turnover  daily_return  \n",
      "56        0.883608      0.027498  \n",
      "57        0.280253      0.009004  \n",
      "58        0.579970      0.005935  \n",
      "59        1.000740     -0.002709  \n",
      "60        0.332719     -0.008591  \n",
      "61        0.539553     -0.017670  \n",
      "62        0.904711      0.004114  \n",
      "63        1.521310      0.006962  \n",
      "64        0.473727      0.000840  \n",
      "65        0.258485     -0.210503  \n",
      "\n",
      "Transactions (tail):\n",
      "       trade_dt   signal_dt ticker  ticker_id  side    shares   price  \\\n",
      "598  2025-09-29  2025-09-26   INTC        241   BUY  0.738106   34.52   \n",
      "599  2025-09-29  2025-09-26    NEM        332   BUY  0.460371   87.59   \n",
      "600  2025-09-30  2025-09-29    GLW        206  SELL -0.125244   80.26   \n",
      "601  2025-09-30  2025-09-29   INTC        241  SELL -0.270593   33.93   \n",
      "602  2025-09-30  2025-09-29   LRCX        286   BUY  0.231850  131.35   \n",
      "603  2025-09-30  2025-09-29    NEM        332  SELL -0.095964   83.57   \n",
      "604  2025-10-01  2025-09-30    CAT         76   BUY  0.064301  474.01   \n",
      "605  2025-10-01  2025-09-30    GLW        206  SELL -0.005275   81.46   \n",
      "606  2025-10-01  2025-09-30   INTC        241   BUY  0.011471   33.53   \n",
      "607  2025-10-01  2025-09-30   LRCX        286  SELL -0.001663  132.41   \n",
      "\n",
      "        dollar            reason  \n",
      "598  25.479415  rebalance_target  \n",
      "599  40.323906  rebalance_target  \n",
      "600 -10.052097  rebalance_target  \n",
      "601  -9.181215  rebalance_target  \n",
      "602  30.453493  rebalance_target  \n",
      "603  -8.019721  rebalance_target  \n",
      "604  30.479089  rebalance_target  \n",
      "605  -0.429727  rebalance_target  \n",
      "606   0.384611  rebalance_target  \n",
      "607  -0.220165  rebalance_target  \n",
      "\n",
      "Final positions:\n",
      "  ticker  ticker_id    shares  avg_cost  entry_date\n",
      "0    GLW        206  0.374160     81.46  2025-10-01\n",
      "1   INTC        241  0.909010     33.53  2025-10-01\n",
      "2    NEM        332  0.364407     83.57  2025-09-30\n",
      "3   LRCX        286  0.230187    132.41  2025-10-01\n",
      "4    CAT         76  0.064301    474.01  2025-10-01\n"
     ]
    }
   ],
   "source": [
    "# BACKTEST OF DAILY PORTFOLIO. WITH COLUMNS DATE AND TICKERS\n",
    "\n",
    "from bisect import bisect_right\n",
    "import duckdb, pandas as pd\n",
    "\n",
    "# ====== SETTINGS ======\n",
    "DB_PATH = \"/Users/martingobbo/stock-dashboard/data/serving/analytics.duckdb\"\n",
    "INITIAL_CAPITAL = 100.0  # change if you want\n",
    "\n",
    "# ====== INPUT: daily_long ======\n",
    "# Expecting a pandas DataFrame `daily_long` already in memory with columns: ['date','ticker']\n",
    "daily_long = daily_portfolio.copy()\n",
    "daily_long['date'] = pd.to_datetime(daily_long['date']).dt.date\n",
    "daily_long['ticker'] = daily_long['ticker'].astype(str).str.strip().str.upper()\n",
    "daily_long = daily_long.drop_duplicates(subset=['date','ticker']).sort_values(['date','ticker'])\n",
    "\n",
    "# Remove any stale ticker_id columns\n",
    "for col in list(daily_long.columns):\n",
    "    if col == 'ticker_id' or col.startswith('ticker_id') or col.endswith('.1'):\n",
    "        daily_long = daily_long.drop(columns=col)\n",
    "\n",
    "# ====== CONNECT & LOAD REFS ======\n",
    "con = duckdb.connect(DB_PATH, read_only=True)\n",
    "\n",
    "dim_ticker = con.execute(\"\"\"\n",
    "    SELECT ticker, ticker_id\n",
    "    FROM dim_ticker\n",
    "\"\"\").df()\n",
    "dim_ticker['ticker'] = dim_ticker['ticker'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# ====== MAP TICKER -> TICKER_ID ======\n",
    "ticker_to_id = dict(zip(dim_ticker['ticker'], dim_ticker['ticker_id']))\n",
    "daily_long['ticker_id'] = daily_long['ticker'].map(ticker_to_id)\n",
    "\n",
    "missing = sorted(daily_long.loc[daily_long['ticker_id'].isna(), 'ticker'].unique())\n",
    "if missing:\n",
    "    print(f\"[WARN] {len(missing)} tickers not found in dim_ticker and will be skipped:\")\n",
    "    print(missing[:50] + (['...'] if len(missing) > 50 else []))\n",
    "\n",
    "daily_long = (\n",
    "    daily_long.dropna(subset=['ticker_id'])\n",
    "              .assign(ticker_id=lambda df: df['ticker_id'].astype('int64'))\n",
    "              .drop_duplicates(subset=['date','ticker_id'])\n",
    "              .sort_values(['date','ticker_id'])\n",
    ")\n",
    "\n",
    "if daily_long.empty:\n",
    "    con.close()\n",
    "    raise ValueError(\"No tickers in daily_long could be mapped to dim_ticker.ticker_id. Fix tickers and retry.\")\n",
    "\n",
    "# ====== PRICE PULL (include adj_close) ======\n",
    "start_dt = daily_long['date'].min()\n",
    "end_dt   = daily_long['date'].max()\n",
    "\n",
    "ticker_ids = sorted(daily_long['ticker_id'].unique().tolist())\n",
    "if not ticker_ids:\n",
    "    con.close()\n",
    "    raise ValueError(\"No ticker_ids to fetch prices for (after mapping).\")\n",
    "\n",
    "ids_sql = \",\".join(str(int(x)) for x in ticker_ids)\n",
    "\n",
    "prices = con.execute(f\"\"\"\n",
    "    WITH p AS (\n",
    "        SELECT\n",
    "            dt,\n",
    "            ticker_id,\n",
    "            open,\n",
    "            close,\n",
    "            adj_close\n",
    "        FROM fact_price_daily\n",
    "        WHERE ticker_id IN ({ids_sql})\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM p\n",
    "    WHERE dt >= DATE '{start_dt}' - INTERVAL 2 DAY\n",
    "      AND dt <= DATE '{end_dt}'   + INTERVAL 10 DAY\n",
    "\"\"\").df()\n",
    "\n",
    "con.close()\n",
    "\n",
    "if prices.empty:\n",
    "    raise ValueError(\"No price rows returned for the requested tickers/date range from fact_price_daily. Check contents and column names.\")\n",
    "\n",
    "# Clean price dtypes\n",
    "prices['dt'] = pd.to_datetime(prices['dt']).dt.date\n",
    "\n",
    "# ====== GLOBAL TRADING CALENDAR ======\n",
    "cal = sorted(prices['dt'].unique())\n",
    "if not cal:\n",
    "    raise ValueError(\"Trading calendar is empty (no distinct dt values).\")\n",
    "\n",
    "# Fast lookup: MultiIndex\n",
    "px = prices.set_index(['dt','ticker_id']).sort_index()\n",
    "\n",
    "def get_open(d, tid):\n",
    "    try:\n",
    "        return float(px.loc[(d, tid), 'open'])\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_adj_close(d, tid):\n",
    "    try:\n",
    "        val = px.loc[(d, tid), 'adj_close']\n",
    "        return None if pd.isna(val) else float(val)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_close(d, tid):\n",
    "    try:\n",
    "        val = px.loc[(d, tid), 'close']\n",
    "        return None if pd.isna(val) else float(val)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def next_trading_day(d):\n",
    "    \"\"\"Next dt strictly after d using calendar 'cal'.\"\"\"\n",
    "    i = bisect_right(cal, d)\n",
    "    if i >= len(cal):\n",
    "        return None\n",
    "    return cal[i]\n",
    "\n",
    "# ---------- BACKTEST STATE ----------\n",
    "cash = float(INITIAL_CAPITAL)\n",
    "positions = {}  # ticker_id -> {'shares': float, 'avg_cost': float, 'entry_date': date}\n",
    "prior_total_value = cash\n",
    "\n",
    "ledger_rows = []\n",
    "equity_rows = []\n",
    "\n",
    "# Pre-group signals by date -> set of ticker_ids\n",
    "signals_by_date = (\n",
    "    daily_long.groupby('date')['ticker_id']\n",
    "    .apply(lambda s: sorted(set(s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# ---------- MAIN LOOP ----------\n",
    "for t in sorted(signals_by_date.keys()):\n",
    "    target_tids = signals_by_date[t]\n",
    "\n",
    "    # Execution/valuation day\n",
    "    trade_dt = next_trading_day(t)\n",
    "    if trade_dt is None:\n",
    "        break\n",
    "\n",
    "    # Tradable = has valid open\n",
    "    tradable = []\n",
    "    for tid in target_tids:\n",
    "        if get_open(trade_dt, tid) is not None:\n",
    "            tradable.append(tid)\n",
    "\n",
    "    # Current holdings\n",
    "    current_held = sorted(positions.keys())\n",
    "\n",
    "    # 1) SELL everything not in today's tradable targets\n",
    "    sell_list = []\n",
    "    for tid in current_held:\n",
    "        if tid not in tradable:\n",
    "            opx = get_open(trade_dt, tid)\n",
    "            if opx is not None and positions[tid]['shares'] != 0.0:\n",
    "                shares_to_sell = positions[tid]['shares']\n",
    "                proceeds = shares_to_sell * opx\n",
    "                cash += proceeds\n",
    "                ledger_rows.append({\n",
    "                    'trade_dt': trade_dt,\n",
    "                    'signal_dt': t,\n",
    "                    'ticker_id': tid,\n",
    "                    'side': 'SELL',\n",
    "                    'shares': shares_to_sell,\n",
    "                    'price': opx,\n",
    "                    'dollar': proceeds,\n",
    "                    'reason': 'rebalance_remove'\n",
    "                })\n",
    "                sell_list.append(tid)\n",
    "\n",
    "    for tid in sell_list:\n",
    "        positions.pop(tid, None)\n",
    "\n",
    "    # 2) BUY (equal weight) for tradable targets\n",
    "    if len(tradable) > 0:\n",
    "        base_value_for_targets = prior_total_value\n",
    "        target_weight = 1.0 / len(tradable)\n",
    "        target_dollars_each = base_value_for_targets * target_weight\n",
    "\n",
    "        for tid in tradable:\n",
    "            opx = get_open(trade_dt, tid)\n",
    "            if opx is None or opx <= 0:\n",
    "                continue\n",
    "            desired_shares = target_dollars_each / opx\n",
    "            current_shares = positions.get(tid, {}).get('shares', 0.0)\n",
    "            delta_shares = desired_shares - current_shares\n",
    "            if abs(delta_shares) > 0:\n",
    "                notional = delta_shares * opx\n",
    "                cash -= notional\n",
    "                ledger_rows.append({\n",
    "                    'trade_dt': trade_dt,\n",
    "                    'signal_dt': t,\n",
    "                    'ticker_id': tid,\n",
    "                    'side': 'BUY' if delta_shares > 0 else 'SELL',\n",
    "                    'shares': delta_shares,\n",
    "                    'price': opx,\n",
    "                    'dollar': notional,\n",
    "                    'reason': 'rebalance_target'\n",
    "                })\n",
    "                positions[tid] = {\n",
    "                    'shares': desired_shares,\n",
    "                    'avg_cost': opx,\n",
    "                    'entry_date': trade_dt\n",
    "                }\n",
    "\n",
    "    # 3) MARK at adj_close (fallback close → open)\n",
    "    equity_value = 0.0\n",
    "    for tid, pos in positions.items():\n",
    "        px_val = get_adj_close(trade_dt, tid)\n",
    "        if px_val is None:\n",
    "            px_val = get_close(trade_dt, tid)\n",
    "        if px_val is None:\n",
    "            px_val = get_open(trade_dt, tid) or 0.0\n",
    "        equity_value += pos['shares'] * px_val\n",
    "\n",
    "    total_value = equity_value + cash\n",
    "    traded_dollars = sum(abs(r['dollar']) for r in ledger_rows if r['trade_dt'] == trade_dt)\n",
    "    turnover = traded_dollars / prior_total_value if prior_total_value > 0 else 0.0\n",
    "    daily_ret = (total_value / prior_total_value - 1.0) if prior_total_value > 0 else 0.0\n",
    "\n",
    "    equity_rows.append({\n",
    "        'date': trade_dt,\n",
    "        'equity_value': equity_value,\n",
    "        'cash': cash,\n",
    "        'total_value': total_value,\n",
    "        'num_names': len(positions),\n",
    "        'gross_turnover': turnover,\n",
    "        'daily_return': daily_ret\n",
    "    })\n",
    "\n",
    "    prior_total_value = total_value\n",
    "\n",
    "# ---------- OUTPUT DATAFRAMES ----------\n",
    "transactions = pd.DataFrame(ledger_rows)\n",
    "equity_curve = pd.DataFrame(equity_rows).sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Join tickers for readability\n",
    "if not transactions.empty:\n",
    "    transactions = transactions.merge(dim_ticker[['ticker_id','ticker']], on='ticker_id', how='left')\n",
    "    transactions = transactions[['trade_dt','signal_dt','ticker','ticker_id','side','shares','price','dollar','reason']]\n",
    "\n",
    "final_positions = (\n",
    "    pd.DataFrame([{'ticker_id': tid, **pos} for tid, pos in positions.items()])\n",
    "      .merge(dim_ticker[['ticker_id','ticker']], on='ticker_id', how='left')\n",
    "      [['ticker','ticker_id','shares','avg_cost','entry_date']]\n",
    "    if len(positions) > 0 else pd.DataFrame(columns=['ticker','ticker_id','shares','avg_cost','entry_date'])\n",
    ")\n",
    "\n",
    "# Quick peeks\n",
    "print(\"Equity curve (tail):\")\n",
    "print(equity_curve.tail(10))\n",
    "print(\"\\nTransactions (tail):\")\n",
    "print(transactions.tail(10))\n",
    "print(\"\\nFinal positions:\")\n",
    "print(final_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f70a3-f5a4-4008-b4c6-62af8bbcb6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713046d-5958-4619-a786-ab5eb70bc425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02d4a0-b6ee-4ddb-a989-e7a2058b4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe2a9f-e721-4fa2-b2f2-f59444ac42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE HISTORICAL SIGNALSTREGTH DF TO CSV\n",
    "\n",
    "import os\n",
    "\n",
    "# Save CSV in the current working directory\n",
    "csv_path = os.path.join(os.getcwd(), \"output.csv\")\n",
    "\n",
    "ultra_signals_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved DataFrame to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6707e5-18b4-4f17-88e2-5ba55a657b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAX SIGNAL STRENGTH DAILY\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is ultra_signals_df\n",
    "\n",
    "# Ensure 'date' is datetime type\n",
    "ultra_signals_df['date'] = pd.to_datetime(ultra_signals_df['date']).dt.date\n",
    "\n",
    "# Group by date and find max signal\n",
    "daily_max = (\n",
    "    ultra_signals_df\n",
    "    .groupby('date', as_index=False)['signal']\n",
    "    .max()\n",
    "    .rename(columns={'signal': 'max_signal'})\n",
    ")\n",
    "\n",
    "# Display a scrollable table in Jupyter\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_rows\", 200)  # adjust number of rows shown at once\n",
    "display(daily_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4da0d-6eaa-4c1a-84ff-9880b00e79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT HOW MANY TICKERS IN THE SIGNAL DAILY\n",
    "\n",
    "# Assuming your DataFrame is ultra_signals_df\n",
    "\n",
    "# Ensure 'date' is datetime type\n",
    "ultra_signals_df['date'] = pd.to_datetime(ultra_signals_df['date']).dt.date\n",
    "\n",
    "# Group by date and count signals\n",
    "daily_count = (\n",
    "    ultra_signals_df\n",
    "    .groupby('date', as_index=False)['signal']\n",
    "    .count()\n",
    "    .rename(columns={'signal': 'count_signal'})\n",
    ")\n",
    "\n",
    "# Display a scrollable table in Jupyter\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_rows\", 200)  # adjust number of rows shown at once\n",
    "display(daily_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d01a04-27bc-4c87-a3f8-5dcb04d71ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3517469f-f815-46a6-9e08-d85a69c8b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE DAY VERSION TO GET DAILY SIGNAL STRENGTH\n",
    "\n",
    "# --- Signal Strength Replication in Python (Ultra Bullish / Bearish / Breakout Down) ---\n",
    "# Requirements: duckdb, pandas, numpy\n",
    "import duckdb, pandas as pd, numpy as np\n",
    "\n",
    "# ====== DB CONNECT ======\n",
    "db_path = \"/Users/martingobbo/stock-dashboard/data/serving/analytics.duckdb\"\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# ====== CONFIG — metric codes exactly matching dim_metric.metric_code ======\n",
    "METRIC_CODES = [\n",
    "    # Price\n",
    "    'moving_avg_20d','moving_avg_50d','moving_avg_200d',\n",
    "    '5_day_range_pos',\n",
    "    'change_10dayret',\n",
    "    'slope_over60_of_logprice','prior_slope_over60_of_logprice','60d_return_accel',\n",
    "    '10_day_ret','60_day_ret','200_day_ret','300_day_ret',\n",
    "    # Volume\n",
    "    'abn_vol_60d',\n",
    "    '60d_price_dollarVolume_correlation',\n",
    "    '252d_dollar_volume_accel',\n",
    "    '60d_dollar_volume_SMA','252d_dollar_volume_SMA',\n",
    "    # Volatility\n",
    "    '252d_upsidevolatility','252d_downsidedeviation',\n",
    "    'slope_over20_of_60d_volatility','slope_over60_of_252d_volatility',\n",
    "    '5d_EMA_15dayvolatility','60d_volatility',\n",
    "    '60_10_highlowrange_zscore',\n",
    "    # Drawdown\n",
    "    '750d_drawdown',\n",
    "    'drawdown_percent'\n",
    "]\n",
    "\n",
    "# ====== Helpers ======\n",
    "def clamp(v, lo, hi):\n",
    "    try:\n",
    "        return max(lo, min(hi, v))\n",
    "    except Exception:\n",
    "        return lo\n",
    "\n",
    "def nz(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    try:\n",
    "        xx = float(x)\n",
    "        if np.isnan(xx):\n",
    "            return None\n",
    "        return xx\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ====== 1) Resolve metric ids (no fragile f-strings) and latest date ======\n",
    "codes_df = pd.DataFrame({'metric_code': METRIC_CODES})\n",
    "con.register('codes_df', codes_df)\n",
    "\n",
    "met = con.execute(\"\"\"\n",
    "    SELECT d.metric_code, d.metric_id\n",
    "    FROM dim_metric d\n",
    "    JOIN codes_df c ON c.metric_code = d.metric_code\n",
    "\"\"\").df()\n",
    "\n",
    "if met.empty:\n",
    "    raise RuntimeError(\"No metric_id found for the requested METRIC_CODES in dim_metric.\")\n",
    "\n",
    "code_to_id = dict(zip(met.metric_code, met.metric_id))\n",
    "id_to_code = dict(zip(met.metric_id, met.metric_code))\n",
    "metric_id_csv = \",\".join(str(i) for i in met.metric_id)\n",
    "\n",
    "latest_dt = con.execute(f\"\"\"\n",
    "    SELECT CAST(MAX(CAST(dt AS DATE)) AS DATE) AS max_dt\n",
    "    FROM fact_metric_daily\n",
    "    WHERE metric_id IN ({metric_id_csv})\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "if latest_dt is None:\n",
    "    raise RuntimeError(\"Could not find latest dt in fact_metric_daily for the requested metrics.\")\n",
    "\n",
    "# ====== 2) Pull latest rows and pivot to wide by metric_code ======\n",
    "vals = con.execute(f\"\"\"\n",
    "    SELECT t.ticker, f.metric_id, f.value\n",
    "    FROM fact_metric_daily f\n",
    "    JOIN dim_ticker t USING (ticker_id)\n",
    "    WHERE CAST(f.dt AS DATE) = DATE '{latest_dt}'\n",
    "      AND f.metric_id IN ({metric_id_csv})\n",
    "      AND t.ticker IS NOT NULL AND LENGTH(TRIM(t.ticker)) > 0\n",
    "\"\"\").df()\n",
    "\n",
    "if vals.empty:\n",
    "    raise RuntimeError(f\"No fact_metric_daily rows on {latest_dt} for requested metrics.\")\n",
    "\n",
    "vals[\"metric_code\"] = vals[\"metric_id\"].map(id_to_code)\n",
    "latest_wide = vals.pivot_table(\n",
    "    index=\"ticker\", columns=\"metric_code\", values=\"value\", aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "# Ensure all needed columns exist (fill missing with NaN)\n",
    "for col in METRIC_CODES:\n",
    "    if col not in latest_wide.columns:\n",
    "        latest_wide[col] = np.nan\n",
    "\n",
    "def g(row, key):\n",
    "    return nz(row.get(key))\n",
    "\n",
    "# ====== 3) SCORING FUNCTIONS — mirror the JS logic ======\n",
    "\n",
    "# ---- ULTRA BULLISH ----\n",
    "def gate_ultra(row):\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    zAbn = g(row,'abn_vol_60d')\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    priceOK = (r10 is not None and r10 >= 0.02) and (r60 is not None and r60 >= 0.05)\n",
    "    volOK   = ((zAbn is not None and zAbn > 0.3) or (corr is not None and corr > 0.5))\n",
    "    return priceOK and volOK\n",
    "\n",
    "def score_price_ultra(row):\n",
    "    pts = 0.0\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "    if ma20 is not None and ma50 not in (None, 0):\n",
    "        rel = (ma20/ma50) - 1\n",
    "        if rel > 0:\n",
    "            pts += 6 * clamp(rel/0.10, 0, 1)\n",
    "    if ma50 is not None and ma200 not in (None, 0):\n",
    "        rel = (ma50/ma200) - 1\n",
    "        if rel > 0:\n",
    "            pts += 6 * clamp(rel/0.10, 0, 1)\n",
    "    pos = g(row,'5_day_range_pos') or 0\n",
    "    pos = clamp(pos, 0, 1)\n",
    "    pts += 8 * pos\n",
    "    ch10 = g(row,'change_10dayret')\n",
    "    if ch10 is not None and ch10 > 0:\n",
    "        pts += 4\n",
    "    s60  = g(row,'slope_over60_of_logprice')\n",
    "    s60p = g(row,'prior_slope_over60_of_logprice')\n",
    "    accel60 = g(row,'60d_return_accel')\n",
    "    if (s60 is not None and s60p is not None and (s60 - s60p) > 0) or (accel60 is not None and accel60 > 0):\n",
    "        pts += 3\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    if r10 is not None and r10 > 0:\n",
    "        pts += 5 * clamp(r10/0.10, 0, 1)\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    if r60 is not None and r60 > 0:\n",
    "        pts += 6 * clamp(r60/0.25, 0, 1)\n",
    "    r300 = g(row,'300_day_ret')\n",
    "    if r300 is not None and r300 > 0:\n",
    "        pts += 4 * clamp(r300/0.50, 0, 1)\n",
    "    return clamp(pts, 0, 45)\n",
    "\n",
    "def score_volume_ultra(row):\n",
    "    pts = 0.0\n",
    "    z = g(row,'abn_vol_60d')\n",
    "    if z is not None:\n",
    "        pts += 8 * clamp(z/2, 0, 1)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    if corr is not None:\n",
    "        pts += 7 * clamp(corr, 0, 1)\n",
    "    accel252 = g(row,'252d_dollar_volume_accel')\n",
    "    if accel252 is not None and accel252 > 0:\n",
    "        pts += 5\n",
    "    sma60, sma252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    if sma60 is not None and sma252 not in (None, 0):\n",
    "        rel = (sma60/sma252) - 1\n",
    "        if rel > 0:\n",
    "            pts += 8 * clamp(rel/0.20, 0, 1)\n",
    "    return clamp(pts, 0, 28)\n",
    "\n",
    "def score_vola_ultra(row):\n",
    "    pts = 0.0\n",
    "    up252, dn252 = g(row,'252d_upsidevolatility'), g(row,'252d_downsidedeviation')\n",
    "    if up252 is not None and dn252 not in (None, 0) and (up252/dn252) > 1:\n",
    "        pts += 5\n",
    "    slope60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    if slope60 is not None and slope60 <= 0:\n",
    "        pts += 5\n",
    "    slope252 = g(row,'slope_over60_of_252d_volatility')\n",
    "    if slope252 is not None and slope252 < 0:\n",
    "        pts += 4\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    if ema15 is not None and vol60 not in (None, 0) and (ema15/vol60) < 1:\n",
    "        pts += 8\n",
    "    return clamp(pts, 0, 22)\n",
    "\n",
    "def score_drawdown_ultra(row):\n",
    "    pts = 0.0\n",
    "    dd750 = g(row,'750d_drawdown')\n",
    "    if dd750 is not None:\n",
    "        pts += 2 * (1 - clamp(abs(dd750)/0.40, 0, 1))\n",
    "    dd100 = g(row,'drawdown_percent')\n",
    "    if dd100 is not None:\n",
    "        pts += 3 * (1 - clamp(abs(dd100)/0.20, 0, 1))\n",
    "    return clamp(pts, 0, 5)\n",
    "\n",
    "# ---- BEARISH ----\n",
    "def gate_bearish(row):\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    zAbn = g(row,'abn_vol_60d')\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    priceOK = (r10 is not None and r10 <= -0.02) and (r60 is not None and r60 <= -0.05)\n",
    "    volOK   = ((zAbn is not None and zAbn > 0.3) or (corr is not None and corr > 0.5))\n",
    "    return priceOK and volOK\n",
    "\n",
    "def score_price_bearish(row):\n",
    "    pts = 0.0\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "    if ma20 is not None and ma50 not in (None, 0):\n",
    "        rel = (ma20/ma50) - 1\n",
    "        if rel < 0:\n",
    "            pts += 6 * clamp((-rel)/0.10, 0, 1)\n",
    "    if ma50 is not None and ma200 not in (None, 0):\n",
    "        rel2 = (ma50/ma200) - 1\n",
    "        if rel2 < 0:\n",
    "            pts += 6 * clamp((-rel2)/0.10, 0, 1)\n",
    "    pos = g(row,'5_day_range_pos') or 0\n",
    "    pos = clamp(pos, 0, 1)\n",
    "    pts += 8 * (1 - pos)\n",
    "    ch10 = g(row,'change_10dayret')\n",
    "    if ch10 is not None and ch10 < 0:\n",
    "        pts += 4\n",
    "    s60  = g(row,'slope_over60_of_logprice')\n",
    "    s60p = g(row,'prior_slope_over60_of_logprice')\n",
    "    accel60 = g(row,'60d_return_accel')\n",
    "    if (s60 is not None and s60p is not None and (s60 - s60p) < 0) or (accel60 is not None and accel60 < 0):\n",
    "        pts += 3\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    if r10 is not None and r10 < 0:\n",
    "        pts += 5 * clamp((-r10)/0.10, 0, 1)\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    if r60 is not None and r60 < 0:\n",
    "        pts += 6 * clamp((-r60)/0.25, 0, 1)\n",
    "    r300 = g(row,'300_day_ret')\n",
    "    if r300 is not None and r300 < 0:\n",
    "        pts += 4 * clamp((-r300)/0.50, 0, 1)\n",
    "    return clamp(pts, 0, 45)\n",
    "\n",
    "def score_volume_bearish(row):\n",
    "    pts = 0.0\n",
    "    z = g(row,'abn_vol_60d')\n",
    "    if z is not None:\n",
    "        pts += 8 * clamp(z/2, 0, 1)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    if corr is not None:\n",
    "        pts += 7 * clamp(-corr, 0, 1)\n",
    "    accel252 = g(row,'252d_dollar_volume_accel')\n",
    "    if accel252 is not None and accel252 > 0:\n",
    "        pts += 5\n",
    "    sma60, sma252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    if sma60 is not None and sma252 not in (None, 0):\n",
    "        rel = (sma60/sma252) - 1\n",
    "        if rel > 0:\n",
    "            pts += 8 * clamp(rel/0.20, 0, 1)\n",
    "    return clamp(pts, 0, 28)\n",
    "\n",
    "def score_vola_bearish(row):\n",
    "    pts = 0.0\n",
    "    up252, dn252 = g(row,'252d_upsidevolatility'), g(row,'252d_downsidedeviation')\n",
    "    if up252 is not None and dn252 not in (None, 0) and (up252/dn252) < 1:\n",
    "        pts += 5\n",
    "    slope60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    if slope60 is not None and slope60 >= 0:\n",
    "        pts += 5\n",
    "    slope252 = g(row,'slope_over60_of_252d_volatility')\n",
    "    if slope252 is not None and slope252 > 0:\n",
    "        pts += 4\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    if ema15 is not None and vol60 not in (None, 0) and (ema15/vol60) > 1:\n",
    "        pts += 8\n",
    "    return clamp(pts, 0, 22)\n",
    "\n",
    "def score_drawdown_bearish(row):\n",
    "    pts = 0.0\n",
    "    dd750 = g(row,'750d_drawdown')\n",
    "    if dd750 is not None:\n",
    "        pts += 2 * clamp(abs(dd750)/0.40, 0, 1)\n",
    "    dd100 = g(row,'drawdown_percent')\n",
    "    if dd100 is not None:\n",
    "        pts += 3 * clamp(abs(dd100)/0.20, 0, 1)\n",
    "    return clamp(pts, 0, 5)\n",
    "\n",
    "# ---- BREAKOUT DOWN ----\n",
    "def gate_breakdown(row):\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    pos5 = g(row,'5_day_range_pos')\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "\n",
    "    priceFresh = (r10 is not None and r10 < 0.02) and (r60 is not None and r60 > -0.10)\n",
    "    nearLows = (pos5 is not None and pos5 <= 0.15)\n",
    "    freshFlip = ((ma20 is not None and ma50 is not None and ma20 < ma50) or\n",
    "                 (ma50 is not None and ma200 is not None and ma50 < ma200))\n",
    "\n",
    "    zAbn = g(row,'abn_vol_60d')\n",
    "    dv60, dv252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    liqUpshift = (dv60 is not None and dv252 not in (None, 0) and (dv60/dv252) >= 1.15)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    volConfirm = ((zAbn is not None and zAbn >= 0.5) or liqUpshift or (corr is not None and corr <= -0.2))\n",
    "\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    shortVsInter = (ema15 is not None and vol60 not in (None, 0) and (ema15/vol60) > 1)\n",
    "\n",
    "    slope20of60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    zRange = g(row,'60_10_highlowrange_zscore')\n",
    "    dd100 = g(row,'drawdown_percent')\n",
    "    volaConfirm = (\n",
    "        shortVsInter\n",
    "        or (slope20of60 is not None and slope20of60 >= 0)\n",
    "        or (zRange is not None and zRange >= 0.25)\n",
    "        or (dd100 is not None and dd100 > 0.15)\n",
    "    )\n",
    "    return priceFresh and nearLows and freshFlip and volConfirm and volaConfirm\n",
    "\n",
    "def score_price_breakdown(row):\n",
    "    pts = 0.0\n",
    "    ma20, ma50, ma200 = g(row,'moving_avg_20d'), g(row,'moving_avg_50d'), g(row,'moving_avg_200d')\n",
    "    if ma20 is not None and ma50 not in (None, 0):\n",
    "        rel = (ma20/ma50) - 1\n",
    "        if rel < 0:\n",
    "            pts += 6 * clamp((-rel)/0.05, 0, 1)\n",
    "    if ma50 is not None and ma200 not in (None, 0):\n",
    "        rel2 = (ma50/ma200) - 1\n",
    "        if rel2 < 0:\n",
    "            pts += 6 * clamp((-rel2)/0.05, 0, 1)\n",
    "    s60  = g(row,'slope_over60_of_logprice')\n",
    "    s60p = g(row,'prior_slope_over60_of_logprice')\n",
    "    if s60 is not None and s60p is not None:\n",
    "        delta = s60 - s60p\n",
    "        if delta <= 0:\n",
    "            pts += 10 * clamp((-delta)/0.02, 0, 1)\n",
    "    r10 = g(row,'10_day_ret')\n",
    "    if r10 is not None and r10 < -0.02:\n",
    "        pts += 5\n",
    "    r60 = g(row,'60_day_ret')\n",
    "    if r60 is not None:\n",
    "        if r60 > 0:\n",
    "            pts += 5\n",
    "        elif r60 >= -0.10:\n",
    "            pts += 2\n",
    "    r200 = g(row,'200_day_ret')\n",
    "    if r200 is not None:\n",
    "        pts += (8 if r200 > 0 else 3)\n",
    "    return clamp(pts, 0, 40)\n",
    "\n",
    "def score_volume_breakdown(row):\n",
    "    pts = 0.0\n",
    "    z = g(row,'abn_vol_60d')\n",
    "    if z is not None:\n",
    "        pts += 10 * clamp(z/1.85, 0, 1)\n",
    "    dv60, dv252 = g(row,'60d_dollar_volume_SMA'), g(row,'252d_dollar_volume_SMA')\n",
    "    if dv60 is not None and dv252 not in (None, 0):\n",
    "        rel = (dv60/dv252) - 1\n",
    "        pts += 8 * clamp(rel/0.20, 0, 1)\n",
    "    corr = g(row,'60d_price_dollarVolume_correlation')\n",
    "    if corr is not None:\n",
    "        pts += 7 * clamp(-corr, 0, 1)\n",
    "    return clamp(pts, 0, 25)\n",
    "\n",
    "def score_vola_breakdown(row):\n",
    "    pts = 0.0\n",
    "    ema15, vol60 = g(row,'5d_EMA_15dayvolatility'), g(row,'60d_volatility')\n",
    "    if ema15 is not None and vol60 not in (None, 0):\n",
    "        ratio = ema15/vol60\n",
    "        if ratio > 1:\n",
    "            pts += 10 * clamp((ratio - 1)/0.50, 0, 1)\n",
    "    slope20of60 = g(row,'slope_over20_of_60d_volatility')\n",
    "    if slope20of60 is not None and slope20of60 >= 0:\n",
    "        pts += 8 * clamp(slope20of60/0.02, 0, 1)\n",
    "    zRange = g(row,'60_10_highlowrange_zscore')\n",
    "    if zRange is not None:\n",
    "        pts += 7 * clamp(zRange/1.8, 0, 1)\n",
    "    return clamp(pts, 0, 25)\n",
    "\n",
    "def score_drawdown_breakdown(row):\n",
    "    pts = 0.0\n",
    "    dd = g(row,'drawdown_percent')\n",
    "    if dd is not None and dd <= 0.20:\n",
    "        pts += 6 * (1 - clamp(abs(dd)/0.20, 0, 1))\n",
    "    dd750 = g(row,'750d_drawdown')\n",
    "    if dd750 is not None:\n",
    "        pts += 4 * (1 - clamp(abs(dd750)/0.40, 0, 1))\n",
    "    return clamp(pts, 0, 10)\n",
    "\n",
    "# ====== 4) Apply scoring to each ticker ======\n",
    "records = latest_wide.to_dict(orient=\"records\")\n",
    "\n",
    "ultra_rows, bearish_rows, breakdown_rows = [], [], []\n",
    "\n",
    "for r in records:\n",
    "    ticker = r[\"ticker\"]\n",
    "\n",
    "    if gate_ultra(r):\n",
    "        total = clamp(\n",
    "            score_price_ultra(r) + score_volume_ultra(r) + score_vola_ultra(r) + score_drawdown_ultra(r),\n",
    "            0, 100\n",
    "        )\n",
    "        ultra_rows.append({\"ticker\": ticker, \"signal\": round(total, 3)})\n",
    "\n",
    "    if gate_bearish(r):\n",
    "        total = clamp(\n",
    "            score_price_bearish(r) + score_volume_bearish(r) + score_vola_bearish(r) + score_drawdown_bearish(r),\n",
    "            0, 100\n",
    "        )\n",
    "        bearish_rows.append({\"ticker\": ticker, \"signal\": round(total, 3)})\n",
    "\n",
    "    if gate_breakdown(r):\n",
    "        total = clamp(\n",
    "            score_price_breakdown(r) + score_volume_breakdown(r) + score_vola_breakdown(r) + score_drawdown_breakdown(r),\n",
    "            0, 100\n",
    "        )\n",
    "        breakdown_rows.append({\"ticker\": ticker, \"signal\": round(total, 3)})\n",
    "\n",
    "# ====== 5) DataFrames (sorted by signal desc) ======\n",
    "ultra_df = pd.DataFrame(ultra_rows).sort_values([\"signal\",\"ticker\"], ascending=[False, True]).reset_index(drop=True)\n",
    "bearish_df = pd.DataFrame(bearish_rows).sort_values([\"signal\",\"ticker\"], ascending=[False, True]).reset_index(drop=True)\n",
    "breakdown_df = pd.DataFrame(breakdown_rows).sort_values([\"signal\",\"ticker\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Latest metric date: {latest_dt}\")\n",
    "print(\"Ultra Bullish matches:\", len(ultra_df))\n",
    "print(\"Bearish matches:\", len(bearish_df))\n",
    "print(\"Breakout Down matches:\", len(breakdown_df))\n",
    "\n",
    "# Keep raw wide metrics as well (preview heads)\n",
    "latest_wide_head = latest_wide.head()\n",
    "ultra_head = ultra_df.head()\n",
    "bearish_head = bearish_df.head()\n",
    "breakdown_head = breakdown_df.head()\n",
    "\n",
    "latest_wide_head, ultra_head, bearish_head, breakdown_head\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
