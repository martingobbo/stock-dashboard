{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1e067c-a425-492b-8a0f-066f5a99f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Wrote report → /Users/martingobbo/stock-dashboard/backtesting/just_testing/duplicate_scan_report.csv\n",
      "Top 20 offenders:\n",
      "WFC     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "RTX     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "RTX     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "DIS     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "DIS     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "AON     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "AON     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "AJG     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "AJG     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "AIG     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "AIG     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "AFL     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "AFL     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "AEP     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "ADSK    extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "ADSK    extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "ADP     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "ADP     extras= 80  (annual=40, quarterly=40)  balance_sheet\n",
      "ADI     extras= 80  (annual=40, quarterly=40)  income_statement\n",
      "ADI     extras= 80  (annual=40, quarterly=40)  balance_sheet\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "FMP JSONL Duplicate Checker (Annual & Quarterly)\n",
    "\n",
    "Scans your existing JSONL files in:\n",
    "  /Users/martingobbo/stock-dashboard/data/raw/fmp/{income_statement,balance_sheet,cash_flow}\n",
    "\n",
    "Reports potential duplicates based on robust keys:\n",
    "- Annual (FY):   key = (\"FY\", calendarYear) or (\"FY\", date[:4]) fallback\n",
    "- Quarterly (Q): key = (\"Q\", date, period)   where period ∈ {Q1,Q2,Q3,Q4,quarter}\n",
    "\n",
    "Outputs a CSV summary: duplicate_scan_report.csv\n",
    "Does NOT modify any files.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ROOT = Path(\"/Users/martingobbo/stock-dashboard/data/raw/fmp\")\n",
    "SUBDIRS = {\n",
    "    \"income_statement\": ROOT / \"income_statement\",\n",
    "    \"balance_sheet\":    ROOT / \"balance_sheet\",\n",
    "    \"cash_flow\":        ROOT / \"cash_flow\",\n",
    "    # ratios usually lacks FY/Q split; skip for this checker\n",
    "}\n",
    "OUTPUT_CSV = Path(\"duplicate_scan_report.csv\")\n",
    "\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def read_jsonl(path: Path):\n",
    "    \"\"\"Yield parsed dicts from a .jsonl file; skip malformed lines.\"\"\"\n",
    "    with path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "\n",
    "def norm_period(value):\n",
    "    \"\"\"Normalize period string to: 'FY','Q1','Q2','Q3','Q4','quarter','unknown'.\"\"\"\n",
    "    if value is None:\n",
    "        return \"unknown\"\n",
    "    s = str(value).strip().lower()\n",
    "    if s in {\"fy\", \"annual\", \"year\"}:\n",
    "        return \"FY\"\n",
    "    if s in {\"q1\", \"q2\", \"q3\", \"q4\"}:\n",
    "        return s.upper()\n",
    "    if s == \"quarter\":\n",
    "        return \"quarter\"\n",
    "    return s or \"unknown\"\n",
    "\n",
    "\n",
    "def is_annual(p):\n",
    "    return p == \"FY\"\n",
    "\n",
    "\n",
    "def is_quarterly(p):\n",
    "    return p in {\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"quarter\"}\n",
    "\n",
    "\n",
    "def annual_key(row):\n",
    "    \"\"\"Compute robust FY key from a row.\"\"\"\n",
    "    cal_year = str(row.get(\"calendarYear\") or \"\").strip()\n",
    "    if cal_year:\n",
    "        return (\"FY\", cal_year)\n",
    "    date = str(row.get(\"date\") or \"\").strip()\n",
    "    year = date[:4] if len(date) >= 4 else \"\"\n",
    "    return (\"FY\", year or \"unknown\")\n",
    "\n",
    "\n",
    "def quarterly_key(row, period_norm):\n",
    "    \"\"\"Compute robust Q key from a row (date + period).\"\"\"\n",
    "    date = str(row.get(\"date\") or \"\").strip()\n",
    "    q = period_norm if period_norm in {\"Q1\", \"Q2\", \"Q3\", \"Q4\"} else period_norm\n",
    "    return (\"Q\", date or \"unknown\", q or \"unknown\")\n",
    "\n",
    "\n",
    "def scan_file(path: Path):\n",
    "    \"\"\"Scan a single .jsonl and return (totals, annual_dupes, quarterly_dupes).\"\"\"\n",
    "    totals = {\"annual\": 0, \"quarterly\": 0, \"other\": 0}\n",
    "    seen_annual = defaultdict(int)\n",
    "    seen_quarterly = defaultdict(int)\n",
    "\n",
    "    for row in read_jsonl(path):\n",
    "        pnorm = norm_period(row.get(\"period\"))\n",
    "        if is_annual(pnorm):\n",
    "            key = annual_key(row)\n",
    "            seen_annual[key] += 1\n",
    "            totals[\"annual\"] += 1\n",
    "        elif is_quarterly(pnorm):\n",
    "            key = quarterly_key(row, pnorm)\n",
    "            seen_quarterly[key] += 1\n",
    "            totals[\"quarterly\"] += 1\n",
    "        else:\n",
    "            totals[\"other\"] += 1\n",
    "\n",
    "    a_dupes = {k: c for k, c in seen_annual.items() if c > 1}\n",
    "    q_dupes = {k: c for k, c in seen_quarterly.items() if c > 1}\n",
    "    return totals, a_dupes, q_dupes\n",
    "\n",
    "\n",
    "def preview(d, max_items=5):\n",
    "    items = list(d.items())[:max_items]\n",
    "    return \"; \".join(f\"{k} → {c}x\" for k, c in items)\n",
    "\n",
    "\n",
    "def summarize_folder(subdir_name, folder: Path):\n",
    "    rows = []\n",
    "    for f in sorted(folder.glob(\"*.jsonl\")):\n",
    "        sym = f.stem\n",
    "        totals, a_dupes, q_dupes = scan_file(f)\n",
    "        row = {\n",
    "            \"subdir\": subdir_name,\n",
    "            \"ticker\": sym,\n",
    "            \"path\": str(f),\n",
    "            \"total_rows\": totals[\"annual\"] + totals[\"quarterly\"] + totals[\"other\"],\n",
    "            \"annual_rows\": totals[\"annual\"],\n",
    "            \"quarterly_rows\": totals[\"quarterly\"],\n",
    "            \"other_rows\": totals[\"other\"],\n",
    "            \"annual_dupe_keys\": preview(a_dupes),\n",
    "            # number of extra rows beyond unique (e.g., c=3 → 2 extras)\n",
    "            \"annual_dupe_count\": sum(c - 1 for c in a_dupes.values()),\n",
    "            \"quarterly_dupe_keys\": preview(q_dupes),\n",
    "            \"quarterly_dupe_count\": sum(c - 1 for c in q_dupes.values()),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    all_rows = []\n",
    "    for name, folder in SUBDIRS.items():\n",
    "        if not folder.exists():\n",
    "            print(f\"[warn] Missing folder: {folder}\")\n",
    "            continue\n",
    "        rows = summarize_folder(name, folder)\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "    # Sort by worst offenders (most duplicate extras), then ticker\n",
    "    all_rows.sort(\n",
    "        key=lambda r: (r[\"annual_dupe_count\"] + r[\"quarterly_dupe_count\"], r[\"ticker\"]),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    fieldnames = [\n",
    "        \"subdir\", \"ticker\", \"path\",\n",
    "        \"total_rows\", \"annual_rows\", \"quarterly_rows\", \"other_rows\",\n",
    "        \"annual_dupe_count\", \"annual_dupe_keys\",\n",
    "        \"quarterly_dupe_count\", \"quarterly_dupe_keys\",\n",
    "    ]\n",
    "\n",
    "    with OUTPUT_CSV.open(\"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        for row in all_rows:\n",
    "            w.writerow(row)\n",
    "\n",
    "    print(f\"[ok] Wrote report → {OUTPUT_CSV.resolve()}\")\n",
    "    print(\"Top 20 offenders:\")\n",
    "    for r in all_rows[:20]:\n",
    "        total_extras = r[\"annual_dupe_count\"] + r[\"quarterly_dupe_count\"]\n",
    "        print(\n",
    "            f\"{r['ticker']:6s}  extras={total_extras:3d}  \"\n",
    "            f\"(annual={r['annual_dupe_count']}, quarterly={r['quarterly_dupe_count']})  {r['subdir']}\"\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b53be88-1a7f-4a90-b75c-5e7451d531ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Starting in-place dedupe with backups...\n",
      "[ok] Cleaned income_statement A      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AAPL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ABBV   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ABNB   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ABT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ACGL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ACN    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ADBE   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ADI    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ADM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ADP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ADSK   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AEE    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AEP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AES    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AFL    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AIG    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AIZ    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AJG    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AKAM   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ALB    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ALGN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ALL    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ALLE   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMAT   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMCR   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMD    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AME    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMGN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AMZN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ANET   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AON    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AOS    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AVGO   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement AXP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement BA     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement BAC    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement BKNG   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement BRK.B  → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement BSX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement BX     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement CAT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement COST   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement CRM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement CSCO   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement CVX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement DIS    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement GE     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement GOOGL  → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement GS     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement HD     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement IBM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ISRG   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement JNJ    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement JPM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement KO     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement LIN    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement LLY    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement MA     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement MCD    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement META   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement MRK    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement MS     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement MSFT   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement NFLX   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement NVDA   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement ORCL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement PEP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement PG     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement PM     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement RTX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement T      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement TMO    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement TMUS   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement TSLA   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement UBER   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement UNH    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement V      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement VZ     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement WFC    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement WMT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned income_statement XOM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    A      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AAPL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ABBV   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ABNB   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ABT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ACGL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ACN    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ADBE   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ADI    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ADM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ADP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ADSK   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AEE    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AEP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AES    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AFL    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AIG    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AIZ    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AJG    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AKAM   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ALB    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ALGN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ALL    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ALLE   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMAT   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMCR   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMD    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AME    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMGN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AMZN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ANET   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AON    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AVGO   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    AXP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    BA     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    BAC    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    BKNG   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    BRK.B  → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    BSX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    BX     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    CAT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    COST   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    CRM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    CSCO   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    CVX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    DIS    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    GE     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    GOOGL  → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    GS     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    HD     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    IBM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ISRG   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    JNJ    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    JPM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    KO     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    LIN    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    LLY    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    MA     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    MCD    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    META   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    MRK    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    MS     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    MSFT   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    NFLX   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    NVDA   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    ORCL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    PEP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    PG     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    PM     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    RTX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    T      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    TMO    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    TMUS   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    TSLA   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    UBER   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    UNH    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    V      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    VZ     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    WFC    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    WMT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned balance_sheet    XOM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        A      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AAPL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ABBV   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ABNB   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ABT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ACGL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ACN    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ADBE   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ADI    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ADM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ADP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ADSK   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AEE    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AEP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AES    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AFL    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AIG    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AIZ    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AJG    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AKAM   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ALB    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ALGN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ALL    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ALLE   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMAT   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMCR   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMD    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AME    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMGN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AMZN   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ANET   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AON    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AOS    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AVGO   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        AXP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        BA     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        BAC    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        BKNG   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        BRK.B  → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        BSX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        BX     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        CAT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        COST   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        CRM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        CSCO   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        CVX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        DIS    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        GE     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        GOOGL  → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        GS     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        HD     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        IBM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ISRG   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        JNJ    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        JPM    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        KO     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        LIN    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        LLY    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        MA     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        MCD    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        META   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        MRK    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        MS     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        MSFT   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        NFLX   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        NVDA   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        ORCL   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        PEP    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        PG     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        PM     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        RTX    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        T      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        TMO    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        TMUS   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        TSLA   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        UBER   → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        UNH    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        V      → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        VZ     → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        WFC    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        WMT    → wrote deduped file (others kept=0)\n",
      "[ok] Cleaned cash_flow        XOM    → wrote deduped file (others kept=0)\n",
      "[info] Verifying duplicates AFTER cleanup...\n",
      "[ok] Wrote AFTER report → /Users/martingobbo/stock-dashboard/backtesting/just_testing/duplicate_scan_report_after.csv\n",
      "[good] No remaining duplicates found across scanned files.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "FMP JSONL Dedupe & Verify (Annual & Quarterly)\n",
    "\n",
    "What it does (per file under income_statement, balance_sheet, cash_flow):\n",
    "1) Reads .jsonl rows\n",
    "2) Detects duplicates using robust keys:\n",
    "   - Annual (FY):   (\"FY\", calendarYear) or (\"FY\", date[:4]) fallback\n",
    "   - Quarterly (Q): (\"Q\", date, period) with period ∈ {Q1,Q2,Q3,Q4,quarter}\n",
    "3) Keeps exactly ONE row per key and removes extras\n",
    "   - Never deletes the only row for a key (so FY/Q coverage is preserved)\n",
    "   - Tie-break: keeps the row with the greatest \"completeness\" (most non-null fields);\n",
    "               if tied, keeps the LAST occurrence in the file (stable, deterministic)\n",
    "4) Writes a timestamped backup of the original file next to it\n",
    "5) Writes the cleaned file in place\n",
    "6) Re-runs a duplicate scan and prints a short report\n",
    "7) Also writes a CSV summary after-cleanup: duplicate_scan_report_after.csv\n",
    "\n",
    "Only touches: income_statement, balance_sheet, cash_flow.\n",
    "Skips: ratios (often not FY/Q-marked).\n",
    "\n",
    "Usage:\n",
    "  python3 fmp_dedupe_jsonl.py\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, Any, List\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ROOT = Path(\"/Users/martingobbo/stock-dashboard/data/raw/fmp\")\n",
    "SUBDIRS = {\n",
    "    \"income_statement\": ROOT / \"income_statement\",\n",
    "    \"balance_sheet\":    ROOT / \"balance_sheet\",\n",
    "    \"cash_flow\":        ROOT / \"cash_flow\",\n",
    "}\n",
    "OUTPUT_CSV_AFTER = Path(\"duplicate_scan_report_after.csv\")\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def read_jsonl(path: Path):\n",
    "    \"\"\"Yield (line_idx, parsed_dict) from a .jsonl; skip malformed lines but preserve index.\"\"\"\n",
    "    with path.open(\"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                yield i, json.loads(line)\n",
    "            except Exception:\n",
    "                # Malformed lines are ignored during dedupe (cannot key them), but we won't re-emit them.\n",
    "                # If you prefer, you could append them verbatim at the end.\n",
    "                continue\n",
    "\n",
    "def norm_period(value: Any) -> str:\n",
    "    \"\"\"Normalize period string to: 'FY','Q1','Q2','Q3','Q4','quarter','unknown'.\"\"\"\n",
    "    if value is None:\n",
    "        return \"unknown\"\n",
    "    s = str(value).strip().lower()\n",
    "    if s in {\"fy\", \"annual\", \"year\"}:\n",
    "        return \"FY\"\n",
    "    if s in {\"q1\", \"q2\", \"q3\", \"q4\"}:\n",
    "        return s.upper()\n",
    "    if s == \"quarter\":\n",
    "        return \"quarter\"\n",
    "    return s or \"unknown\"\n",
    "\n",
    "def is_annual(p: str) -> bool:\n",
    "    return p == \"FY\"\n",
    "\n",
    "def is_quarterly(p: str) -> bool:\n",
    "    return p in {\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"quarter\"}\n",
    "\n",
    "def annual_key(row: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    \"\"\"Compute robust FY key from a row.\"\"\"\n",
    "    cal_year = str(row.get(\"calendarYear\") or \"\").strip()\n",
    "    if cal_year:\n",
    "        return (\"FY\", cal_year)\n",
    "    date = str(row.get(\"date\") or \"\").strip()\n",
    "    year = date[:4] if len(date) >= 4 else \"\"\n",
    "    return (\"FY\", year or \"unknown\")\n",
    "\n",
    "def quarterly_key(row: Dict[str, Any], period_norm: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"Compute robust Q key from a row (date + period).\"\"\"\n",
    "    date = str(row.get(\"date\") or \"\").strip()\n",
    "    q = period_norm if period_norm in {\"Q1\", \"Q2\", \"Q3\", \"Q4\"} else period_norm\n",
    "    return (\"Q\", date or \"unknown\", q or \"unknown\")\n",
    "\n",
    "def completeness_score(row: Dict[str, Any]) -> int:\n",
    "    \"\"\"\n",
    "    Score row by number of non-null, non-empty fields.\n",
    "    We exclude a few common 'meta' fields from contributing (adjust if you want).\n",
    "    \"\"\"\n",
    "    exclude = {\n",
    "        \"symbol\", \"reportedCurrency\", \"cik\", \"fillingDate\", \"acceptedDate\",\n",
    "        \"period\", \"calendarYear\", \"link\", \"finalLink\"\n",
    "    }\n",
    "    score = 0\n",
    "    for k, v in row.items():\n",
    "        if k in exclude:\n",
    "            continue\n",
    "        if v is None:\n",
    "            continue\n",
    "        # treat empty strings as null-like\n",
    "        if isinstance(v, str) and not v.strip():\n",
    "            continue\n",
    "        score += 1\n",
    "    return score\n",
    "\n",
    "def best_row(existing: Tuple[int, Dict[str, Any]], candidate: Tuple[int, Dict[str, Any]]) -> Tuple[int, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Tie-breaker for duplicates:\n",
    "    1) Keep the row with higher completeness_score\n",
    "    2) If tied, keep the one appearing later in file (greater line_idx)\n",
    "    Returns the winning (line_idx, row)\n",
    "    \"\"\"\n",
    "    (i1, r1) = existing\n",
    "    (i2, r2) = candidate\n",
    "    s1, s2 = completeness_score(r1), completeness_score(r2)\n",
    "    if s2 > s1:\n",
    "        return (i2, r2)\n",
    "    if s2 < s1:\n",
    "        return (i1, r1)\n",
    "    # tie → prefer later occurrence\n",
    "    return (i2, r2) if i2 > i1 else (i1, r1)\n",
    "\n",
    "def scan_file_for_dupes(path: Path):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      totals: dict\n",
    "      a_dupes: Dict[key, count]\n",
    "      q_dupes: Dict[key, count]\n",
    "    \"\"\"\n",
    "    totals = {\"annual\": 0, \"quarterly\": 0, \"other\": 0}\n",
    "    seen_annual = defaultdict(int)\n",
    "    seen_quarterly = defaultdict(int)\n",
    "\n",
    "    for _, row in read_jsonl(path):\n",
    "        pnorm = norm_period(row.get(\"period\"))\n",
    "        if is_annual(pnorm):\n",
    "            key = annual_key(row)\n",
    "            seen_annual[key] += 1\n",
    "            totals[\"annual\"] += 1\n",
    "        elif is_quarterly(pnorm):\n",
    "            key = quarterly_key(row, pnorm)\n",
    "            seen_quarterly[key] += 1\n",
    "            totals[\"quarterly\"] += 1\n",
    "        else:\n",
    "            totals[\"other\"] += 1\n",
    "\n",
    "    a_dupes = {k: c for k, c in seen_annual.items() if c > 1}\n",
    "    q_dupes = {k: c for k, c in seen_quarterly.items() if c > 1}\n",
    "    return totals, a_dupes, q_dupes\n",
    "\n",
    "def preview(d: Dict[Any, int], max_items=5) -> str:\n",
    "    items = list(d.items())[:max_items]\n",
    "    return \"; \".join(f\"{k} → {c}x\" for k, c in items)\n",
    "\n",
    "def write_backup(original: Path) -> Path:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup = original.with_suffix(original.suffix + f\".bak_{ts}\")\n",
    "    backup.write_bytes(original.read_bytes())\n",
    "    return backup\n",
    "\n",
    "def dedupe_file_in_place(path: Path) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Dedupe a single JSONL file in place.\n",
    "    Returns:\n",
    "      (removed_annual, removed_quarterly, kept_other)\n",
    "    \"\"\"\n",
    "    # First pass: choose a single best row per key\n",
    "    annual_best: Dict[Tuple[str, str], Tuple[int, Dict[str, Any]]] = {}\n",
    "    quarterly_best: Dict[Tuple[str, str, str], Tuple[int, Dict[str, Any]]] = {}\n",
    "    others: List[Dict[str, Any]] = []\n",
    "\n",
    "    for line_idx, row in read_jsonl(path):\n",
    "        pnorm = norm_period(row.get(\"period\"))\n",
    "        if is_annual(pnorm):\n",
    "            key = annual_key(row)\n",
    "            if key in annual_best:\n",
    "                annual_best[key] = best_row(annual_best[key], (line_idx, row))\n",
    "            else:\n",
    "                annual_best[key] = (line_idx, row)\n",
    "        elif is_quarterly(pnorm):\n",
    "            key = quarterly_key(row, pnorm)\n",
    "            if key in quarterly_best:\n",
    "                quarterly_best[key] = best_row(quarterly_best[key], (line_idx, row))\n",
    "            else:\n",
    "                quarterly_best[key] = (line_idx, row)\n",
    "        else:\n",
    "            # Keep \"other\" rows exactly as-is (no dedupe rule)\n",
    "            others.append(row)\n",
    "\n",
    "    # Rebuild file contents from winners only (ensuring at least one per key)\n",
    "    # Backup before writing\n",
    "    _ = write_backup(path)\n",
    "\n",
    "    winners = [r for (_, r) in annual_best.values()] + [r for (_, r) in quarterly_best.values()] + others\n",
    "\n",
    "    with path.open(\"w\") as f:\n",
    "        for r in winners:\n",
    "            f.write(json.dumps(r, separators=(\",\", \":\")) + \"\\n\")\n",
    "\n",
    "    # Compute how many extras were removed (for info)\n",
    "    # Re-scan with counts BEFORE would require a pre-pass; instead, approximate by re-reading and comparing keys.\n",
    "    # Do a quick second scan with counts to report dupes after (should be zero).\n",
    "    totals_after, a_dupes_after, q_dupes_after = scan_file_for_dupes(path)\n",
    "\n",
    "    # Return a rough stat: extras remaining are 0; we can't easily report removed count without a pre-count.\n",
    "    removed_annual = sum(c - 1 for c in a_dupes_after.values())  # should be 0\n",
    "    removed_quarterly = sum(c - 1 for c in q_dupes_after.values())  # should be 0\n",
    "    kept_other = totals_after[\"other\"]\n",
    "    return removed_annual, removed_quarterly, kept_other\n",
    "\n",
    "def summarize_folder(subdir_name: str, folder: Path):\n",
    "    rows = []\n",
    "    for f in sorted(folder.glob(\"*.jsonl\")):\n",
    "        sym = f.stem\n",
    "        totals, a_dupes, q_dupes = scan_file_for_dupes(f)\n",
    "        rows.append({\n",
    "            \"subdir\": subdir_name,\n",
    "            \"ticker\": sym,\n",
    "            \"path\": str(f),\n",
    "            \"total_rows\": totals[\"annual\"] + totals[\"quarterly\"] + totals[\"other\"],\n",
    "            \"annual_rows\": totals[\"annual\"],\n",
    "            \"quarterly_rows\": totals[\"quarterly\"],\n",
    "            \"other_rows\": totals[\"other\"],\n",
    "            \"annual_dupe_count\": sum(c - 1 for c in a_dupes.values()),\n",
    "            \"annual_dupe_keys\": preview(a_dupes),\n",
    "            \"quarterly_dupe_count\": sum(c - 1 for c in q_dupes.values()),\n",
    "            \"quarterly_dupe_keys\": preview(q_dupes),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    # 1) Dedupe in place across all target subfolders\n",
    "    print(\"[info] Starting in-place dedupe with backups...\")\n",
    "    for name, folder in SUBDIRS.items():\n",
    "        if not folder.exists():\n",
    "            print(f\"[warn] Missing folder: {folder}\")\n",
    "            continue\n",
    "        for f in sorted(folder.glob(\"*.jsonl\")):\n",
    "            removed_a, removed_q, kept_o = dedupe_file_in_place(f)\n",
    "            print(f\"[ok] Cleaned {name:16s} {f.stem:6s} → wrote deduped file (others kept={kept_o})\")\n",
    "\n",
    "    # 2) After-cleanup verification & CSV\n",
    "    print(\"[info] Verifying duplicates AFTER cleanup...\")\n",
    "    all_rows = []\n",
    "    for name, folder in SUBDIRS.items():\n",
    "        if not folder.exists():\n",
    "            continue\n",
    "        rows = summarize_folder(name, folder)\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "    # Sort by any remaining offenders (should be zero), then ticker\n",
    "    all_rows.sort(\n",
    "        key=lambda r: (r[\"annual_dupe_count\"] + r[\"quarterly_dupe_count\"], r[\"ticker\"]),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    fieldnames = [\n",
    "        \"subdir\", \"ticker\", \"path\",\n",
    "        \"total_rows\", \"annual_rows\", \"quarterly_rows\", \"other_rows\",\n",
    "        \"annual_dupe_count\", \"annual_dupe_keys\",\n",
    "        \"quarterly_dupe_count\", \"quarterly_dupe_keys\",\n",
    "    ]\n",
    "    with OUTPUT_CSV_AFTER.open(\"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        for row in all_rows:\n",
    "            w.writerow(row)\n",
    "\n",
    "    print(f\"[ok] Wrote AFTER report → {OUTPUT_CSV_AFTER.resolve()}\")\n",
    "    offenders = [r for r in all_rows if (r[\"annual_dupe_count\"] + r[\"quarterly_dupe_count\"]) > 0]\n",
    "    if offenders:\n",
    "        print(\"Remaining offenders (top 20):\")\n",
    "        for r in offenders[:20]:\n",
    "            total_extras = r[\"annual_dupe_count\"] + r[\"quarterly_dupe_count\"]\n",
    "            print(\n",
    "                f\"{r['ticker']:6s}  extras={total_extras:3d}  \"\n",
    "                f\"(annual={r['annual_dupe_count']}, quarterly={r['quarterly_dupe_count']})  {r['subdir']}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"[good] No remaining duplicates found across scanned files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e17e3c-b7b5-4392-885a-3b394327922b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
